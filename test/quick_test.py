# --- quick_test.py ---
# Test model Sentiment + Response ri√™ng bi·ªát (robust with any hf_client return)
# -------------------------------------------------------------------
import sys, os, time
import math

# Cho ph√©p import core/* khi ch·∫°y t·ª´ th∆∞ m·ª•c tests/
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from core.hf_client import query_model
from core.config import ROUND_DECIMALS

try:
    import torch
    import torch.nn.functional as F
    _HAS_TORCH = True
except Exception:
    _HAS_TORCH = False

texts = [
    "H√¥m nay t√¥i c·∫£m th·∫•y r·∫•t bu·ªìn, ch·∫≥ng mu·ªën l√†m g√¨ c·∫£.",
    "M√¨nh vui l·∫Øm, v·ª´a nh·∫≠n ƒë∆∞·ª£c h·ªçc b·ªïng! üòÑ",
    "T√¥i h∆°i lo l·∫Øng cho b√†i thi s·∫Øp t·ªõi.",
    "M√¨nh nh·ªõ m·∫π, ch·ªâ mu·ªën v·ªÅ nh√† √¥m m·∫π th√¥i.",
    "T√¥i b·ª±c m√¨nh v√¨ b·ªã ƒëi·ªÉm th·∫•p d√π ƒë√£ c·ªë g·∫Øng.",
]

def _build_probs(sr):
    """
    Tr·∫£ v·ªÅ probs d·∫°ng [neg, neu, pos] ho·∫∑c None n·∫øu kh√¥ng th·ªÉ suy ra.
    ∆Øu ti√™n: probs -> label_distribution(%) -> raw_logits(softmax).
    """
    # 1) probs
    p = sr.get("probs")
    if isinstance(p, (list, tuple)) and len(p) == 3 and any(x is not None for x in p):
        # Normalize nh·∫π ph√≤ng sai s·ªë
        s = float(sum(p)) or 1.0
        return [float(p[0]) / s, float(p[1]) / s, float(p[2]) / s]

    # 2) label_distribution (%)
    dist = sr.get("label_distribution")
    if isinstance(dist, dict) and {"negative","neutral","positive"} <= set(dist.keys()):
        n = float(dist["negative"])
        u = float(dist["neutral"])
        p = float(dist["positive"])
        s = (n + u + p) or 1.0
        return [n/s, u/s, p/s]

    # 3) raw_logits
    logits = sr.get("raw_logits")
    if _HAS_TORCH and isinstance(logits, (list, tuple)) and len(logits) == 3:
        lt = torch.tensor(list(map(float, logits)), dtype=torch.float32)
        probs = F.softmax(lt, dim=-1).tolist()
        return probs

    return None

print("\nüöÄ=== TEST MODEL SENTIMENT + RESPONSE ===üöÄ\n")

for i, text in enumerate(texts, 1):
    print("\n" + "="*80)
    print(f"üß© TEST CASE {i}")
    print(f"üìú Input: {text}")
    print("-"*80)

    t0 = time.time()

    # -------- Sentiment --------
    sentiment_result = query_model("sentiment", text)

    if isinstance(sentiment_result, dict) and "error" in sentiment_result:
        print(f"‚ùå Sentiment error: {sentiment_result.get('error')}")
        print(f"‚Ü™ Payload: {sentiment_result}")
        print(f"üïí Time: {round(time.time()-t0, 2)}s")
        continue

    label = sentiment_result.get("predicted_label", "unknown")
    probs = _build_probs(sentiment_result)

    if probs is None:
        print("‚ö†Ô∏è Kh√¥ng nh·∫≠n ƒë∆∞·ª£c x√°c su·∫•t t·ª´ hf_client. Payload g·ªëc:")
        print(sentiment_result)
        label_distribution = {"negative": 0, "neutral": 0, "positive": 0}
    else:
        label_distribution = {
            "negative": round(probs[0]*100, ROUND_DECIMALS),
            "neutral":  round(probs[1]*100, ROUND_DECIMALS),
            "positive": round(probs[2]*100, ROUND_DECIMALS),
        }

    print(f"üß† Sentiment: {label}")
    print(f"üìä Probabilities: {label_distribution}")

    # -------- Response --------
    # -------- Response --------
    prompt = (
        f"Ng·ªØ c·∫£nh: {text}\n"
        f"C·∫£m x√∫c ng∆∞·ªùi n√≥i: {label}\n"
        f"H√£y vi·∫øt ph·∫£n h·ªìi ng·∫Øn g·ªçn, t·ª± nhi√™n v√† ·∫•m √°p."
    )

    response_result = query_model("response", prompt)

    if isinstance(response_result, dict) and "error" in response_result:
        # Kh√¥ng in l·ªói API d√†i d√≤ng
        response_text = "(fallback) Hi·ªán t·∫°i m√¥ h√¨nh ph·∫£n h·ªìi ƒëang t·∫°m b·∫≠n, nh∆∞ng m√¨nh v·∫´n ·ªü ƒë√¢y ƒë·ªÉ l·∫Øng nghe b·∫°n üåø."
        source = "fallback"
    else:
        response_text = (response_result or {}).get("text", "").strip() or "Kh√¥ng c√≥ ph·∫£n h·ªìi."
        source = "gemini"

    t1 = round(time.time() - t0, 2)

    print("\nüí¨ Gemini Response:")
    print(response_text)
    print(f"\nüïí Time: {t1}s | Source: {source}")

